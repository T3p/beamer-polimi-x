@misc{OpenAI_dota,
	author = {OpenAI},
	year = {2018},
	title = {OpenAI Five},
	howpublished = {\url{https://blog.openai.com/openai-five/}},
	year = {2018}
}

@article{heess2017emergence,
	title={Emergence of locomotion behaviours in rich environments},
	author={Heess, Nicolas and Sriram, Srinivasan and Lemmon, Jay and Merel, Josh and Wayne, Greg and Tassa, Yuval and Erez, Tom and Wang, Ziyu and Eslami, SM and Riedmiller, Martin and others},
	journal={arXiv preprint arXiv:1707.02286},
	year={2017}
}

@article{garcia2015comprehensive,
	author    = {Javier Garc{\'{\i}}a and
	Fernando Fern{\'{a}}ndez},
	title     = {A comprehensive survey on safe reinforcement learning},
	journal   = {J. Mach. Learn. Res.},
	volume    = {16},
	pages     = {1437--1480},
	year      = {2015}
}

@article{amodei2016concrete,
	author    = {Dario Amodei and
	Chris Olah and
	Jacob Steinhardt and
	Paul F. Christiano and
	John Schulman and
	Dan Man{\'{e}}},
	title     = {Concrete Problems in {AI} Safety},
	journal   = {CoRR},
	volume    = {abs/1606.06565},
	year      = {2016}
}

@inproceedings{papini2017adaptive,
	author    = {Matteo Papini and
	Matteo Pirotta and
	Marcello Restelli},
	title     = {Adaptive Batch Size for Safe Policy Gradients},
	booktitle = {{NeurIPS}},
	pages     = {3591--3600},
	year      = {2017}
}

@inproceedings{pirotta2013adaptive,
	author    = {Matteo Pirotta and
	Marcello Restelli and
	Luca Bascetta},
	title     = {Adaptive Step-Size for Policy Gradient Methods},
	booktitle = {{NIPS}},
	pages     = {1394--1402},
	year      = {2013}
}

@article{pirotta2015policy,
	author    = {Matteo Pirotta and
	Marcello Restelli and
	Luca Bascetta},
	title     = {Policy gradient in Lipschitz Markov Decision Processes},
	journal   = {Machine Learning},
	volume    = {100},
	number    = {2-3},
	pages     = {255--283},
	year      = {2015}
}



@inproceedings{schulman2015trust,
	author    = {John Schulman and
	Sergey Levine and
	Pieter Abbeel and
	Michael I. Jordan and
	Philipp Moritz},
	title     = {Trust Region Policy Optimization},
	booktitle = {{ICML}},
	series    = {{JMLR} Workshop and Conference Proceedings},
	volume    = {37},
	pages     = {1889--1897},
	publisher = {JMLR.org},
	year      = {2015}
}

@inproceedings{kakade2002approximately,
	author    = {Sham M. Kakade and
	John Langford},
	title     = {Approximately Optimal Approximate Reinforcement Learning},
	booktitle = {{ICML}},
	pages     = {267--274},
	publisher = {Morgan Kaufmann},
	year      = {2002}
}

@article{lattimore2018bandit,
	title={Bandit algorithms},
	author={Lattimore, Tor and Szepesv{\'a}ri, Csaba},
	year={2018}
}

@article{bubeck2012regret,
	title={Regret analysis of stochastic and nonstochastic multi-armed bandit problems},
	author={Bubeck, S{\'e}bastien and Cesa-Bianchi, Nicolo and others},
	journal={Foundations and Trends{\textregistered} in Machine Learning},
	volume={5},
	number={1},
	pages={1--122},
	year={2012},
	publisher={Now Publishers, Inc.}
}

@article{agarwal2019optimality,
	title={Optimality and Approximation with Policy Gradient Methods in Markov Decision Processes},
	author={Agarwal, Alekh and Kakade, Sham M and Lee, Jason D and Mahajan, Gaurav},
	journal={arXiv preprint arXiv:1908.00261},
	year={2019}
}

@article{bhandari2019global,
	title={Global Optimality Guarantees For Policy Gradient Methods},
	author={Bhandari, Jalaj and Russo, Daniel},
	journal={arXiv preprint arXiv:1906.01786},
	year={2019}
}

@article{shani2019adaptive,
	title={Adaptive Trust Region Policy Optimization: Global Convergence and Faster Rates for Regularized MDPs},
	author={Shani, Lior and Efroni, Yonathan and Mannor, Shie},
	journal={arXiv preprint arXiv:1909.02769},
	year={2019}
}

@inproceedings{papini2018stochastic,
	author    = {Matteo Papini and
	Damiano Binaghi and
	Giuseppe Canonaco and
	Matteo Pirotta and
	Marcello Restelli},
	title     = {Stochastic Variance-Reduced Policy Gradient},
	booktitle = {{ICML}},
	series    = {Proceedings of Machine Learning Research},
	volume    = {80},
	pages     = {4023--4032},
	publisher = {{PMLR}},
	year      = {2018}
}

@inproceedings{xu2019improved,
	author    = {Pan Xu and
	Felicia Gao and
	Quanquan Gu},
	title     = {An Improved Convergence Analysis of Stochastic Variance-Reduced Policy
	Gradient},
	booktitle = {{UAI}},
	pages     = {191},
	publisher = {{AUAI} Press},
	year      = {2019}
}

@article{xu2019sample,
	author    = {Pan Xu and
	Felicia Gao and
	Quanquan Gu},
	title     = {Sample Efficient Policy Gradient Methods with Recursive Variance Reduction},
	journal   = {CoRR},
	volume    = {abs/1909.08610},
	year      = {2019}
}

@article{papini2019smoothing,
	author    = {Matteo Papini and
	Matteo Pirotta and
	Marcello Restelli},
	title     = {Smoothing Policies and Safe Policy Gradients},
	journal   = {CoRR},
	volume    = {abs/1905.03231},
	year      = {2019}
}

@book{sutton2018reinforcement,
	title={Reinforcement learning: An introduction},
	author={Sutton, Richard S and Barto, Andrew G},
	year={2018},
	publisher={MIT press}
}

@article{deisenroth2013survey,
	author    = {Marc Peter Deisenroth and
	Gerhard Neumann and
	Jan Peters},
	title     = {A Survey on Policy Search for Robotics},
	journal   = {Foundations and Trends in Robotics},
	volume    = {2},
	number    = {1-2},
	pages     = {1--142},
	year      = {2013}
}

@inproceedings{sutton1999policy,
	author    = {Richard S. Sutton and
	David A. McAllester and
	Satinder P. Singh and
	Yishay Mansour},
	title     = {Policy Gradient Methods for Reinforcement Learning with Function Approximation},
	booktitle = {{NIPS}},
	pages     = {1057--1063},
	publisher = {The {MIT} Press},
	year      = {1999}
}



@inproceedings{papini2019optimistic,
	author    = {Matteo Papini and
	Alberto Maria Metelli and
	Lorenzo Lupo and
	Marcello Restelli},
	title     = {Optimistic Policy Optimization via Multiple Importance Sampling},
	booktitle = {{ICML}},
	series    = {Proceedings of Machine Learning Research},
	volume    = {97},
	pages     = {4989--4999},
	publisher = {{PMLR}},
	year      = {2019}
}

@inproceedings{metelli2018policy,
	author    = {Alberto Maria Metelli and
	Matteo Papini and
	Francesco Faccio and
	Marcello Restelli},
	title     = {Policy Optimization via Importance Sampling},
	booktitle = {NeurIPS},
	pages     = {5447--5459},
	year      = {2018}
}

@article{beraha2019feature,
	author    = {Mario Beraha and
	Alberto Maria Metelli and
	Matteo Papini and
	Andrea Tirinzoni and
	Marcello Restelli},
	title     = {Feature Selection via Mutual Information: New Theoretical Insights},
	booktitle   = {IJCNN},
	year      = {2019}
}

@inproceedings{zafarali2019understanding,
	author    = {Zafarali Ahmed and
	Nicolas Le Roux and
	Mohammad Norouzi and
	Dale Schuurmans},
	title     = {Understanding the Impact of Entropy on Policy Optimization},
	booktitle = {{ICML}},
	series    = {Proceedings of Machine Learning Research},
	volume    = {97},
	pages     = {151--160},
	publisher = {{PMLR}},
	year      = {2019}
}